\documentclass[12pt]{article}

% This first part of the file is called the PREAMBLE. It includes
% customizations and command definitions. The preamble is everything
% between \documentclass and \begin{document}.

\usepackage[margin=1in]{geometry}  % set the margins to 1in on all sides
\usepackage{graphicx}              % to include figures
\usepackage{amsmath,bm}            % great math stuff
\usepackage{amsfonts}              % for blackboard bold, etc
\usepackage{amsthm}                % better theorem environments
\usepackage{listings}
\usepackage{bbm}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage[]{algorithm2e}
\usepackage{parskip} 			   % no paragraph indentation

\usetikzlibrary{arrows,automata}


% various theorems, numbered by section

\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}[thm]{Conjecture}

\DeclareMathOperator{\id}{id}

\newcommand{\bd}[1]{\mathbf{#1}}  % for bolding symbols
\newcommand{\RR}{\mathbb{R}}      % for Real numbers
\newcommand{\ZZ}{\mathbb{Z}}      % for Integers
\newcommand{\col}[1]{\left[\begin{matrix} #1 \end{matrix} \right]}
\newcommand{\comb}[2]{\binom{#1^2 + #2^2}{#1+#2}}

\lstset{ % General setup for the package
    language={[LaTeX]TeX},
    basicstyle=\footnotesize\sffamily,
    tabsize=4,
    columns=fixed,
    keepspaces,
    commentstyle=\color{red},
    keywordstyle=\color{blue},
    xleftmargin=.1\textwidth,
    xrightmargin=.1\textwidth
}

\begin{document}

\nocite{*}


\title{Discrete Optimization \\
       Assignment 1}

\author{Mehdi Nadif \& Viktor Hansen}

\maketitle

\begin{abstract}
  This is the first weekly assignment for the Discrete Optimization course offered at The Department of Computer Science, Uni. Copenhagen.
\end{abstract}

\pagebreak

\section*{Theoretical part - formulation and lower bounds}
\subsection*{1.1}
\paragraph{Any feasible solution satisfies constraints:} Consider a Hamiltonian tour $p = \pi(1) \rightarrow \pi(2) \rightarrow \hdots \rightarrow \pi(n) \rightarrow \pi(1)$ of $G$ defined by a bijection $\pi : V=\left\{ 1, \hdots, n \right\} \rightarrow \left\{ 1, \hdots, n \right\}$. Let $E_p = \left\{ \left(\pi(i),\pi(i+1) \right) \; | \; 1 \leq i \leq n-1 \right\} \cup \left\{ \left(\pi(n),\pi(1) \right) \right\}$ denote the set of edges traversed by $p$. Then
\begin{align*}
&\sum_{i \in V, i \neq j} x_{ij} = \sum_{i \in V, i \neq j} \mathbbm{1}_{E_p}((i,j)) = 1 \; \; \; \forall j \in V \\
\mathrm{and} \; \; \;  &\sum_{j \in V, j \neq i} x_{ij} = \sum_{j \in V, j \neq i} \mathbbm{1}_{E_p}((i,j)) = 1 \; \; \; \forall i \in V
\end{align*}
since there is exactly one edge entering and leaving and each vertex. To see that $p$ satisfies the subtour constraint, consider any subset $S \subset V$ s.t. $2 \leq |S| \leq n-2$. Then for each such subset $S$,
\begin{align*}
\sum_{i,j \in S} x_{ij} = \sum_{i,j \in S} \mathbbm{1}_{E_p}((i,j)) \leq \sum_{i \in S} \left[ \mathbbm{1}_{E_p}((\pi(i),\pi(i+1))) \right] - 1 = \sum_{i \in S} \left( 1 \right) - 1 = |S| - 1
\end{align*}
This first inequality follows since in the worst case, $S$ forms a Hamiltonian path (i.e. subgraph of the Hamiltonian tour), and this has one edge less than the number of vertices.

\paragraph{Any solution satisfying constraints is feasible:}
To show the other direction, we need to show that an assignment satisfying the constraints correspond to a Hamiltonian tour of G, i.e. that
\begin{enumerate}
\item All vertices are visited exactly once (except for the first vertex)
\item There is only one cycle.
\end{enumerate}
Suppose $\mathbf{x} \in \left\{0,1\right\}^{n \times n}$ is an assignment satisfying the contraints. To show 1), we note that $x_{ij}=1$ iff. there is an edge going from vertex $v_{i}$ to $v_{j}$. For each vertex $v_{k}$ to be visited exactly once, we require that $\sum_{i \in V} x_{ik} = \sum_{j \in V} x_{kj} = 1$, $\forall k \in 1 \hdots n$ which is satisfied by assumption.

To show 2), assume for the sake of contradiction that the feasible solution consists of $k>1$ subtours $p_{1}, \hdots , p_{k}$. The sets of vertices in each such subtour, $p_{i}$, denoted by $L(p_{i})$, form a partition of $V$, so $2 \leq \left| L(p_{i}) \right| \leq n-2$, $1 \leq i \leq k$. Since any subtour $p_{i}$ is a cycle, it has exactly $|L(p_i)|$ edges, and hence $\sum_{i,j \in L(p_{i})} x_{ij} = |L(p_{i})|$ which contradicts the subtour constraint. Hence there can only one cycle.


\subsection*{1.2}

We may first note that 
$$
\sum_{i=0}^n\binom{n}{i} = 2^n
$$
Since $2^n$ is the total number of subsets of a set of size $n$. Since we are only looking at subsets of size between 2 and $n-2$, the number of subsets must be 
\begin{align*}
&2^n - \binom{n}{0} - \binom{n}{1} - \binom{n}{n-1} - \binom{n}{n} \\
&=2^n - 1 - n - n - 1 \\
&= 2^n - 2n - 2 
\end{align*}
since there are as many constraints as subsets, this is also the number of constraints.

\subsection*{1.3}

The number of constraints is equal to the number of combinations of $i \in V, j \in V \backslash\{1\}$. As $|V| = n$, there are $\left|V \times V \setminus \left\{1\right\} \right| = n(n-1)$ constraints.


\subsection*{1.4}
Even though there are many more constraints in the subtour formulation, the variables that have to be optimized are only the $x_{ij}$. As the compact formulation have the additional $t_i, \ i = 1,...,V$ variables to optimize on, branch and bound will be on more variables. Therefore, the depth of the branching tree will be deeper, and it might take more time to get to a feasible solution which could have been used as an incumbent to prune with.

Similarly, one may note that bounding the compact formulation by an LP relaxation yields weak bounds as the $x_{ij}$ can have very low values without breaking constraints. This is observed in a slightly weaker formulation, where we first change the constraints so that
\begin{align*}
t_j & \geq t_i + 1 - n(1 - x_{ij}), \quad i\in V, j\in V\backslash \{1\}\\
\Leftrightarrow \; x_{ij}& \leq  1 - \frac{t_i - t_j + 1}{n}
\end{align*}

if we formulate every combination of $i\in V, j \in V\backslash {1}$ as the set $A$, we may create the weaker bound
\begin{align*}
&\sum_{(i,j)\in A} 1 - \frac{t_i - t_j +1}{n} \geq \sum_{(i,j)\in A} x_{ij}\\
\Leftrightarrow \; & |A| - \sum_{(i,j)\in A} \frac{t_i - t_j + 1}{n} \geq \sum_{(i,j)\in A} x_{ij}\\
\Rightarrow  \; & |A| - \sum_{(i,j)\in A} \frac{1}{n} \geq |A| - \sum_{(i,j)\in A} \frac{t_i - t_j + 1}{n} \geq \sum_{(i,j)\in A} x_{ij}\\
\end{align*}
the last inequality follows since $t_i \leq t_j$ in the optimal case, in which  the bound on the compact formulation is
$$
|A|\left(1 - \sum_{(i,j)\in A} \frac{1}{n}\right) \geq \sum_{(i,j)\in A} x_{ij}
$$

which is a weaker bound than the subtour formulation and may therefore give weaker lower bounds in the branching. 


\subsection*{1.5} 
Consider a minimum-cost Hamiltonian tour $\mathcal{H}$, a minimum spanning tree $\mathcal{M}$ in $G$ and a (possible) leaf-node $v_1$ in $\mathcal{M}$. Since $v_1$ is on $\mathcal{H}$, it has exactly two incident edges $e_\text{min}$ and $e_{\text{max}}$. From $\mathcal{H}$, we remove the most costly of the two edges incident to $v_1$, denoted by $e_{\max}$. Removing this edge, we now have a tree, and therefore
$$
\text{cost}(\mathcal{M}) \leq \text{cost}(\mathcal{H}) - \text{cost}(e_{\max})
$$
since $\mathcal{M}$ is the tree with lowest possible cost. By definition, we must have that $e_{\max} \geq e_\text{min}$ since $e_\text{max}$ was the costlier among the two edges. Therefore
$$
\text{cost}(\mathcal{M}) + \text{cost}(e_\text{min}) \leq \text{cost}(\mathcal{M}) + \text{cost}(e_\text{max}) \leq \text{cost}(\mathcal{H})
$$
and hence the MST with the addition of cheapest edge to a leaf is a lower bound for $\text{cost}(\mathcal{H})$

\pagebreak
\section*{Implementation part - branch-and-bound}
\subsection*{2.1}

There are several upper bounds that can be implemented for this TSP problem, and the ones that we have attempted to implement for this problem were:
\begin{enumerate}
\item {\bf Maximum spanning tree}: First, construct a spanning tree of maximum cost using Kruskal, but chosing the maximum edge at each iteration. Then select the remaining most expensive edge to create a cycle. This should bound the optimal Hamiltonian cycle from above, from the proof in subsection 1.5.
\item {\bf 2-selector}: For each $v\in V$, select the two most expensive edges adjacent to it (assure that edges that are forced to be included in the branch is chosen, and excluded are ignored). Take the sum of all these edges and divide by two to get an upper bound. The division is necessary, since every edge is in two terms of the summation.
\item {\bf Christofides algorithm} for determining an upper bound which is within 3/2 of the optimal solution. Christophide's algorithm does the following:
\begin{enumerate}
\item Compute an MST $T$ of $G$.
\item Select vertices of uneven degree in $T=(E, V, c)$, and store in set $L$.
\item Compute a perfect, minimum cost matching in $L$, denoted by $M$.
\item Determine an Euler tour in $G'=(E \cup M, V, c)$, and shortcut the tour using the triangle inequality where applicable.
\item Return the resulting Hamiltonian tour of G.
\end{enumerate}
\item {\bf MST-walk 2-approximation}: Creates a minimum spanning tree of the graph, and then computes an Euler circuit on this minimum spanning tree which is subsequently short-circuited using the triangle inequality. Weaker than Christofides with an upper bound which is within a factor of 2 of the optimal solution.
\end{enumerate}

As can be seen in Fig. \ref{upperbounds}, the results of each of these heuristics have greatly varying results. Clearly the 2-approximation has the strongest bound on the root node, but it proved quite complex to implement this algorithm so that it worked with the branching, as this required that some edge would be included in the euclidean tour was quite difficult. Also, it seems to be a bound that only gets worse as you decrease the domain of the graph. This is not the case for the {\bf Maximum spanning tree} or the {\bf 2-selector} which both get better at each branching since they always chose worst case for a graph.\\

Unfortunately, none of these upper bounds improved the number of nodes visited from only pruning by lower bounds that are higher than the currently best feasible solution. 
\begin{figure}[!hbt]
\center
\begin{tabular}{|c|c|c|c|}
\hline
&M(ax)ST & 2-selector & 2-approximation\\
\hline
Instance 1 & 31.59 & 31.08 & 8.90 \\
\hline
Instance 2 & 43.02 & 38.71 & 30.83\\
\hline
Instance 3 & 54.38 & 51.82 & 44.86\\
\hline
\end{tabular}
\caption{The upper bounds on the root node problems of the three test instances using three of the above mentioned four upper bound heuristics.\label{upperbounds}}
\end{figure}

\subsection*{2.2}
Solutions using branch-and-bound as well as CPLEX were implemented. The CPLEX solution uses the compact MTZ ILP formulation and does not solve any of the instances within any reasonable time. The branch-and-bound implementation with the lower bound described in 1.5 solves all the instances.

\subsection*{2.3}
The number of branch and bound nodes and the running time for each instance as well as optimal solution values can be seen in Fig. \ref{times}. Despite of being much smaller, a large number of branch-and-bound nodes are generated for instance 1. This might be due to how bounds are computed, as the nodes comprise 2 clusters.
\begin{figure}[!hbt]
\center
\begin{tabular}{|c | c | c | c | c | c |}
\hline
& \multicolumn{3}{|c|}{Branch and bound} & \multicolumn{2}{|c|}{CPLEX} \\
\hline 
& Time/ms & Nodes visited & Path len. & Time & Nodes Visited\\
\hline
Instance 1 & 289.54 & 15133 & 8.649 & \multicolumn{2}{|c|}{N/A} \\
\hline
Instance 2 & 60.72 & 1701 & 19.030 & \multicolumn{2}{|c|}{N/A} \\
\hline
Instance 3 & 586890.74 & 10126850 & 26.753 & \multicolumn{2}{|c|}{N/A} \\
\hline 
\end{tabular}
\caption{Number of branch and bound nodes and the running time for each instance as well as optimal solution values.
\label{times}}
\end{figure}
The CPLEX solution solved no instances within any reasonable time as no pruning takes place when solving the raw ILP. This serves as a testament to the importance of Heuristics, approximations and pruning/cutting techniques such as branch-and-bound.

\end{document}
